# -*- coding: utf-8 -*-
"""server.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZjcfpsvvUcWMwSkaJgFhSWFlRHoT58j
"""

from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torch, os, copy, wandb
import numpy as np
from mIoU import StreamSegMetrics
from collections import OrderedDict
from tqdm import tqdm
'''
In particular, when calling the Server.fedAvg() method, the server will:
1) Select randomly a set of clients between the ones available
2) Request an update to the set of clients sending the global model, in which each client will:
    2.1) Train for a defined number of epochs on the local dataset
    2.2) Return the updated local model parameters
3) Average the updated local models through Federated Averaging algorithm
4) Update the global model
5) Repeat for a defined number of rounds
'''

class Server:
  def __init__(self, 
               server_id: str, 
               model, 
               device,
               clients=None,
               hyperparam = None,
               number_classes = None,
               epochs_per_client = None,
               isstudent=False):
    
    self.model = copy.deepcopy(model)
    self.model_params_dict = copy.deepcopy(self.model.state_dict())
    self.device = device
    self.hyperparam = hyperparam
    self.updates = []
    self.epochs_per_client = epochs_per_client if epochs_per_client is not None else 2
    self.isstudent = isstudent
    self.number_classes = number_classes if number_classes is not None else 19

    self.clients = clients if clients is not None else []

    #self.data_loader = DataLoader(self.dataset, shuffle=True, batch_size=self.batch_size, drop_last=True)

  def load_model_on_client(self, client):
    client.model.load_state_dict(self.model_params_dict)


  def training_fedAvg(self, clients, rounds, t = None, path_server_model=None):
    print("Running FedAvg training...")
    for round in tqdm(range(rounds), desc="Rounds: "):
      if t is not None:
        for client in self.clients:
          client.set_teacher(self.model)

      clients = self.select_clients(round, self.clients)   #Select randomly a set of clients between the ones available

      for cl in clients:

        if self.isstudent:
          num_samples, update = cl.train(self.epochs_per_client, self.hyperparam)  #train each client   - format(epochs, hyperparam, save_path)
        else:
          self.load_model_on_client(cl)     #update each client with the global model
          num_samples, update = cl.train(self.epochs_per_client, self.hyperparam)  #train each client   - format(epochs, hyperparam, save_path)
  
        self.updates.append((num_samples, update))
      
      if t is not None and t == 0:
        pass  
      elif t is not None and t == 1:
        self.update_model(self.updates) #update global model using the updates given by every client
      elif t is not None and t > 1:
        if round % t == 0:
          self.update_model(self.updates)  
        else:
          pass
      
      else:
        self.update_model(self.updates)

        
      checkpoint = {
            "round": round,
            "model_state_dict": self.model.state_dict()
                }
      
      #logging  
      wandb.log({"round": round})
        
      if os.path.exists is not None:
        self.save_model(checkpoint=checkpoint, save_path = path_server_model)
      else:
        self.save_model(checkpoint)
      
    return None
  
  def update_model(self, updates):
    """
    FedAvg on the clients' updates for the current round.
    Weighted average of self.updates, where the weight is given by the number
    of samples seen by the corresponding client at training time.
    Saves the new central model in self.client_model and its state dictionary in self.model
    """
    averaged_sol_n = self._aggregation()  #averaging weights from clients

    self.model.load_state_dict(averaged_sol_n, strict=False)
    self.model_params_dict = copy.deepcopy(self.model.state_dict())
    self.updates = []


  def select_clients(self, my_round, possible_clients, num_clients=5):  #set number of clients per round - on the fedAvg paper num_clients = 5
    num_clients = min(num_clients, len(possible_clients))
    #np.random.seed(my_round)
    return np.random.choice(possible_clients, num_clients, replace=False)


  def _aggregation(self):
    total_weight = 0.
    base = OrderedDict()

    for (client_samples, client_model) in self.updates:

      total_weight += client_samples
      for key, value in client_model.items():
         if key in base:
             base[key] += client_samples * value.type(torch.FloatTensor)
         else:
             base[key] = client_samples * value.type(torch.FloatTensor)
    averaged_sol_n = copy.deepcopy(self.model_params_dict)
    for key, value in base.items():
      if total_weight != 0:
         averaged_sol_n[key] = value.to('cuda') / total_weight

    return averaged_sol_n

  def put_client(self, client):   #add client to list if necessary
    self.clients.append(client)
    print("Client list updated.")
    return 

  def save_model(self, checkpoint=None, save_path=None):
    if save_path is not None and checkpoint is not None:
      torch.save(checkpoint, save_path)
    if save_path is None:
      torch.save(checkpoint=checkpoint)


  def load_model(self, load_path, state_dict=None):
    if os.path.exists(load_path):       #check if the load path exists
      checkpoint = torch.load(load_path)    #load the checkpoint from the path
      self.model.load_state_dict(checkpoint["model_state_dict"])  #load the model state
      self.model.eval()   #set the model to evaluation
      if self.isstudent:
          pass
      else:
          round = checkpoint["round"]
      print(f"Loaded model: {load_path}.")
      return True

    else:
      print(f"Model {load_path} not found")  
      return False

#-----------------------------------------------------------------------#

  def test(self, dataloader=None, cl:str=None):
    self.model.eval() #sets module for inference

    data_loader = dataloader if dataloader is not None else self.data_loader

    images, labels = next(iter(data_loader))  #select the next minibatch of images
    images = images.to(self.device)
    labels = labels.to(self.device, dtype = torch.long)

    outputs, _, _, _, _, = self.model(images)

    _, prediction = outputs.max(dim=1)

    self.plot_sample(prediction[0], images[0], labels[0], cl)
    mIoU_accuracy = self.update_acc(outputs, labels, self.number_classes)

    return mIoU_accuracy

  def update_acc(self, outputs, labels, number_classes):
    #mIoU accuracy calculation - from FedDrive repository (function update_metrics)
    _, prediction = outputs.max(dim=1) # retrieving the predicted label
    labels = labels.cpu().numpy()
    prediction = prediction.cpu().numpy()
    miou = StreamSegMetrics(n_classes=number_classes)
    miou.update(labels,prediction)
    mIoU_accuracy = miou.get_results()["Mean IoU"]
    miou.reset()

    return mIoU_accuracy

  def plot_sample(self, prediction, image, label, cl: str=None):

    image = image.cpu()
    label = label.cpu()
    prediction = prediction.cpu()

    found = True
    if cl is not None:
      map_classes = self.dataset.map_classes
      if cl in map_classes.values():
        for cl, name in enumerate(map_classes.values()):
          if name == cl:
            mapping_pred = prediction==cl
            mapping_label = label==cl
      else:
        print("Class not found")
        flag = True
    
    elif cl is None or not found: 
      mapping_pred = prediction!=255
      mapping_label = label!=255

    plt.imshow(image.permute(1,2,0))
    plt.show()
            
    plt.imshow(prediction*mapping_pred+1, cmap="gray")
    plt.show()
            
    plt.imshow(label*mapping_label+1, cmap="gray")
    plt.show()